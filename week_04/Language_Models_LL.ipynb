{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](NLP_examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `pip install spacy`\n",
    "* `python -m spacy download en_core_web_md` - if this doesn't load, try\n",
    "* `python -m spacy download en_core_web_sm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives:\n",
    "#### * What are the categories of NLP?\n",
    "#### * What is a Language model?\n",
    "#### * See a 'traditional' language model\n",
    "#### * Language Representation areas of interest\n",
    "#### * Introducing Spacy\n",
    "#### * Introducing word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories of NLP:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Representation - translating natural language into 'computer language'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Classification - Input is some language, output is a label describing that language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Generation - Input is some lanaguage, output is some new language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tell me what they are, and where they go!\n",
    "* Sentiment analysis\n",
    "* Speech recognition\n",
    "* Representing Grammar (Syntax)\n",
    "* Relation Extraction\n",
    "* Question Answering\n",
    "* Named Entity Recognition\n",
    "* Representing Meaning (Semantics)\n",
    "* Chatbots\n",
    "* Machine Translation\n",
    "* Dependency grammar\n",
    "* The 'Grammarly' model\n",
    "* Information Summarisation\n",
    "* Language Reasoning\n",
    "* Representing Context (Pragmatics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Language Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A model which tries to assess the liklehood of language\n",
    "* I go home vs I home go - syntax\n",
    "* I go home vs I go house - semantics\n",
    "* I go home vs I go home and tell myself everything is going to be ok cos im so depressed - pragamtics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(W) = P(w_1, w_2, ..., w_n)$\n",
    "\n",
    "or\n",
    "\n",
    "$P(w_{t+1} | w_{t-1+n}, ..., w_{t})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A 'traditional' language model... for Sequence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A bigram Markov chain (more later in the course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_distribution(data):\n",
    "    \"\"\"create a probability distribution over all words\n",
    "    \n",
    "        params: data - a Bunch data object from sklearn\n",
    "        returns: Word probability distribution\n",
    "    \"\"\"\n",
    "\n",
    "    text = data['data']\n",
    "    all_data = ' '.join([' '.join(re.findall('(?u)\\\\b\\\\w\\\\w+\\\\b',article.lower())) for article in text]).split()\n",
    "    words = pd.DataFrame({'words':all_data})\n",
    "    words['next_words'] = words['words'].shift(-1)\n",
    "    word_distribution = words.groupby('words')['next_words'].value_counts(normalize=True)\n",
    "    \n",
    "    return word_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_generation(seed, length, distribution):\n",
    "    \"\"\"seed a distribution with a seed word, and ask it to make more words\n",
    "        \n",
    "        params: seed - A seed word, \n",
    "                length -Length of the generated sentence\n",
    "                distribution - A word probability distribution\n",
    "                \n",
    "        returns: generated sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        seed = seed.lower()\n",
    "        for i in range(length):\n",
    "             seed += ' ' + np.random.choice(distribution[seed.split()[-1]].index, p=distribution[seed.split()[-1]].values)\n",
    "        return seed\n",
    "    \n",
    "    except:\n",
    "        print('Oops! Try another seed')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(remove=['headers', 'footers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the bigram probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = generate_word_distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some new sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = text_generation('It', 20, distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it seems to get ahold of this view of them are discussions belong when the most of burning truck to natural'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Representation areas of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apples -> apple #stemming\n",
    "am -> be # lemmatization \n",
    "an apple and a banana -> apple banana #removing stop words\n",
    "Apple -> apple #lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Preprocessing - tokenization, stop words, lowercase, lemmatization/stemming, normalization\n",
    "#### * Curse of dimensionality\n",
    "#### * Semantic similarity\n",
    "#### * Word order\n",
    "#### * Word sense disambiguation\n",
    "#### * Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solves: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(review, model):\n",
    "    \"\"\"preprocess a string (tokens, stopwords, lowercase, lemma & stemming) returns the cleaned result\n",
    "        params: review - a string\n",
    "                model - a spacy model\n",
    "                \n",
    "        returns: list of cleaned tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    new_doc = []\n",
    "    doc = model(review)\n",
    "    for word in doc:\n",
    "        if not word.is_stop and word.is_alpha:\n",
    "            new_doc.append(word.lemma_.lower())\n",
    "            \n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('this is a document', nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Similarity in BOW!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](orthogonal_BOW.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solves: Semantic similarity, curse of dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_my_word(word, model):\n",
    "    try:\n",
    "        return model.vocab[word].vector.reshape(-1,1).T\n",
    "    except:\n",
    "        print(\"Doesn't look like this word can be found\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_my_word('apple', nlp).shape #one word is 2d, then a list of words is 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen = vectorize_my_word('queen', nlp)\n",
    "king = vectorize_my_word('king', nlp)\n",
    "man = vectorize_my_word('man', nlp)\n",
    "woman = vectorize_my_word('woman', nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_queen = king - man + woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78808445]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(new_queen, queen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.725261]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(queen, king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "princess= vectorize_my_word('princess', nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6578181]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(queen, princess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can I do with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pratical takeaway1: \n",
    "* Use the spacy cleaning function, or onethat you write yourself, on your corpus, to reduce dimensionality, and get better performance on the downstream task (artist prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pratical takeaway2: \n",
    "* try and use word2vec vectors in place of BOW on your ML prediction \n",
    "* CAVEAT! ML models we use accept 2d inputs only, but you might find yourself with a 3Dinput \n",
    "* QUESTION? How can I transform my 3D input into 2D so that MLmodels accept it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
