{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv',  index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing info\n",
    "sns.heatmap(df.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of data\n",
    "sns.pairplot(df, hue='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strength of correlation: feature-feature, and feature-dependent variable\n",
    "# using an absolte correlation as it is the magnitude of correlation, not direction, that we are interested in\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr().abs(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Survived']\n",
    "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(X, agemean):\n",
    "    \"\"\"adds extra features to a DataFrame\"\"\"\n",
    "    X['Age'].fillna(agemean, inplace=True)\n",
    "    # one-hot encoding\n",
    "    X['female'] = (X['Sex']=='female').astype(int)\n",
    "    X['child'] = (X['Age'] < 14).astype(int)\n",
    "    # interaction terms\n",
    "    X['female_pclass'] = X['female']       * X['Pclass']\n",
    "    X['male_pclass']   = (1 - X['female']) * X['Pclass']\n",
    "    X['child_pclass']  = X['child']        * X['Pclass']\n",
    "    X['adult_pclass']  = (1 - X['child'])  * X['Pclass']\n",
    "    del X['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.copy()\n",
    "Xtest = Xtest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agemeans = df.groupby(['Pclass','Sex'])['Age'].mean()\n",
    "\n",
    "agemean = Xtrain['Age'].mean()\n",
    "feature_engineering(Xtrain, agemean)\n",
    "feature_engineering(Xtest, agemean)  # use training mean to avoid 'data leakage' in .mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate the model and intepret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_all = cross_val_score(m, Xtrain, ytrain, cv=10, scoring='accuracy')\n",
    "cv_mean = cv_all.mean()\n",
    "cv_std = np.std(cv_all)\n",
    "f\"Cross-validation mean {cv_mean:5.3f} +- {cv_std:5.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualise a distribution of the results\n",
    "plt.bar(range(10), cv_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(Xtrain, ytrain)\n",
    "train_score = m.score(Xtrain, ytrain)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the score inside the range?\n",
    "train_score > cv_all.min() and train_score < cv_all.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the score is inside one sigma?\n",
    "train_score - cv_mean < cv_std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = m.score(Xtest, ytest)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the models predictive power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = m.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise the confusion matrix - its easier to interpret\n",
    "norm_cm = (confusion_matrix(ytest, ypred) / confusion_matrix(ytest, ypred).sum()) * 100\n",
    "norm_cm = norm_cm.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(norm_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve\n",
    "ypred_proba = m.predict_proba(Xtest)[:,1]\n",
    "fpr, tpr, threshold = roc_curve(ytest, ypred_proba)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('false positive rate / precision')\n",
    "plt.ylabel('true positive rate / recall')\n",
    "plt.title('roc curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the strength of the coefficients for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(range(10), m.coef_[0])\n",
    "plt.yticks(range(10), X.columns)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the statistical significance of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.discrete.discrete_model as sm\n",
    "\n",
    "logit = sm.Logit(ytrain, Xtrain)\n",
    "f = logit.fit(maxiter=300)\n",
    "print(f.params)\n",
    "print('-' * 40)\n",
    "print(f.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "m = RandomForestClassifier(n_estimators=20, max_depth=2)\n",
    "cross_val_score(m, Xtrain, ytrain, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(Xtrain, ytrain)\n",
    "m.score(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(range(10), m.feature_importances_)\n",
    "plt.yticks(range(10), Xtrain.columns)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
