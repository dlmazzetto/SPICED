{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function in Logistic Regression\n",
    "\n",
    "## Random Variable\n",
    "\n",
    "A coin toss is a random variable. We cannot possibly predict the result of the coin toss with certainty.\n",
    "\n",
    "## 0) What are possible events of one coin toss?\n",
    "\n",
    "- Head\n",
    "- Tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) What is a fair coin?\n",
    "\n",
    "If the probability of observing either event of a coin toss is 50%.\n",
    "\n",
    "$P(Heads) = p = 0.5$<br>\n",
    "$P(Tails) = 1-p = 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) What is the probability of observing Heads when you toss a fair coin?\n",
    "\n",
    "P(Kopf) = p = 0.5\n",
    "\n",
    "The coin toss follows a **Bernoulli Distribution**. The **Bernoulli Distribution** is a probability distribution for random variables with two possible events.\n",
    "\n",
    "Heads: y = 1 (like Survived = 1)<br>\n",
    "Tails: y = 0 (like Survived = 0)\n",
    "\n",
    "$$\n",
    "P(y) = \\begin{cases} p &\\mbox{if } y = 1 \\\\\n",
    "   1-p & \\mbox{if } y = 0\n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "or (equivalently)\n",
    "\n",
    "$$\n",
    "P(y) = p^y * (1-p)^{1-y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) What is the probability of observing the sequence of events (*Heads*, *Heads*) if a coin is tossed twice?\n",
    "\n",
    "$$\n",
    "P(Heads, Heads) = p * p = 0.25\n",
    "$$\n",
    "\n",
    "Equivalently it could be written as\n",
    "\n",
    "$$\n",
    "P(Heads, Heads) = P(Heads) * P(Heads)\n",
    "$$\n",
    "\n",
    "or as\n",
    "\n",
    "$$\n",
    "P(Heads, Heads) = (p^{y_1} * (1-p)^{1-y_1}) * (p^{y_2} * (1-p)^{1-y_2})\n",
    "$$\n",
    "\n",
    "oder \n",
    "\n",
    "$$\n",
    "P(Heads, Heads) = \\prod_{i=1}^2 p^{y_i} * (1-p)^{1-y_i}\n",
    "$$\n",
    "\n",
    "--> **The probability of observing a sequence of events can be written as the product of individual probabilities of bernoulli distributed random variables.**\n",
    "\n",
    "Generally:\n",
    "\n",
    "$$\n",
    "P(y_1,...,y_n) = \\prod_{i=1}^N p^{y_i} * (1-p)^{1-y_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Let's turn around the question\n",
    "\n",
    "**So far**: If we know *p*, what is the probability of observing a certain sequence of events?\n",
    "\n",
    "**New**: If we observe a certain sequence of events in the real world, what does that tell us about *p*?\n",
    "\n",
    "If we observe the sequence \n",
    "\n",
    "- Heads, Heads, Heads, Tails\n",
    "\n",
    "and we do not know whether our coin is fair or not, what can we say about *p*?\n",
    "\n",
    "- We will never know with certainty!!!\n",
    "- Our best guess of what *p* is, is the value for which P(Heads, Heads, Heads, Tails) is highest.\n",
    "\n",
    "We turn the probability of the sequence occuring under p\n",
    "\n",
    "$$\n",
    "P(Kopf, Kopf, Kopf, Zahl) = \\prod_{i=1}^4 p^y_i * (1-p)^{1-y_i} = p * p * p * (1-p)\n",
    "$$\n",
    "\n",
    "into a likelihood-function of an estimate of *p* - *$\\hat{p}$*\n",
    "\n",
    "$$\n",
    "L(\\hat{p}) = \\prod_{i=1}^4 \\hat{p}^y_i * (1-\\hat{p})^{1-y_i} = \\hat{p} * \\hat{p} * \\hat{p} * (1-\\hat{p})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihoods(p_hat, sequence):\n",
    "    '''\n",
    "    Calculates the likelihood of observing a sequence of\n",
    "    independent Bernoulli trial.\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    \n",
    "    p_hat:    Estimate of p\n",
    "    sequence: Observed sequence of events\n",
    "    '''\n",
    "    return (p_hat**np.array(sequence) * (1-p_hat)**(1-np.array(sequence))).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.125, 0.25 , 0.375, 0.5  , 0.625, 0.75 , 0.875, 1.   ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Werte f√ºr p die wir ausprobieren wollen\n",
    "probabilities = np.linspace(0, 1, 9)\n",
    "\n",
    "# H, H, H, T\n",
    "sequence = [1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood of observing the sequence [1, 1, 1, 0] if p is 0.0 is 0.0\n",
      "The likelihood of observing the sequence [1, 1, 1, 0] if p is 0.125 is 0.002\n",
      "The likelihood of observing the sequence [1, 1, 1, 0] if p is 0.25 is 0.012\n",
      "The likelihood of observing the sequence [1, 1, 1, 0] if p is 0.375 is 0.033\n",
      "The likelihood of observing the sequence [1, 1, 1, 0] if p is 0.5 is 0.062\n",
      "The likelihood of observing the sequence [1, 1, 1, 0] if p is 0.625 is 0.092\n",
      "The likelihood of observing the sequence [1, 1, 1, 0] if p is 0.75 is 0.105\n",
      "The likelihood of observing the sequence [1, 1, 1, 0] if p is 0.875 is 0.084\n",
      "The likelihood of observing the sequence [1, 1, 1, 0] if p is 1.0 is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Find the best value for p\n",
    "for probability in probabilities:\n",
    "    print(f'The likelihood of observing the sequence {sequence} if p is {probability} \\\n",
    "is {round(calculate_likelihoods(probability, sequence), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Which probability are we interested in in the Titanic project?\n",
    "\n",
    "What are the events?<br>\n",
    "**Events**: Survived, Died\n",
    "\n",
    "P(Survived) = p<br>\n",
    "P(Died) = 1-p\n",
    "\n",
    "## 6) We are more interested in conditional probabilities\n",
    "\n",
    "P(Survived|Age,Sex,Pclass) = p<br>\n",
    "P(Died|Age,Sex,Pclass) = 1-p\n",
    "\n",
    "## 7) The probabilities have to be estimated for all possible combinations of X\n",
    "\n",
    "--> That is what the sigmoid function does.<br>\n",
    "--> The coefficients $b, w_1, w_2,...,w_n$ are estimated such that the likelihood is maximized.\n",
    "\n",
    "$$\n",
    "\\hat{p} = \\frac{1}{1+e^{-(b + w_1*Age + w_2*Sex + w_3*Pclass)}}\n",
    "$$\n",
    "\n",
    "## 8) Likelihood Function\n",
    "\n",
    "$$\n",
    "L(\\hat{p}) = \\prod_{i=1}^N \\hat{p}^{y_i} * (1-\\hat{p})^{1-y_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Log-Likelihood Function\n",
    "\n",
    "Mathematical optimization is easier if a function is additive.\n",
    "\n",
    "- Taking the logarithm turns the product into a sum.\n",
    "- The parameters that maximize a function are the same as the parameters that maximize the logarithm of the function.\n",
    "\n",
    "$$\n",
    "log(L(\\hat{p})) = \\sum_{i=1}^N y_i * log(\\hat{p}) + (1-y_i) * log((1-\\hat{p}))\n",
    "$$\n",
    "\n",
    "## 10) Loss Function\n",
    "\n",
    "The loss function is just the negative log-likelihood function.\n",
    "\n",
    "Maximizing a function is the same as minimizing its negative transformation.\n",
    "\n",
    "$$\n",
    "Loss = -log(L(\\hat{p})) = - \\sum_{i=1}^N y_i * log(\\hat{p}) + (1-y_i) * log((1-\\hat{p}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression maximizes the likelihood of the observed sequence to occur by tweaking its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_own(p_hat, sequence):\n",
    "    '''\n",
    "    Calculates the overall probability of observing a sequence of independent\n",
    "    independent Bernoulli trial.\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    \n",
    "    p_hat:    Estimate of p\n",
    "    sequence: Observed sequence of events\n",
    "    '''\n",
    "    return - (np.log(p_hat)*np.array(sequence) + np.log((1-p_hat))*(1-np.array(sequence))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us import the titanic data\n",
    "df = pd.read_csv('train.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At this point you would go through the following steps:\n",
    "- Assign X and y and train_test_split\n",
    "- EDA\n",
    "- Feature Engineering\n",
    "- Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Pclass']]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.84371207]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w: slope\n",
    "m.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.43255005])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b: position at x=0\n",
    "m.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us have a look at the loss\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7499951 , 0.2500049 ],\n",
       "       [0.35690152, 0.64309848],\n",
       "       [0.7499951 , 0.2500049 ],\n",
       "       ...,\n",
       "       [0.7499951 , 0.2500049 ],\n",
       "       [0.35690152, 0.64309848],\n",
       "       [0.7499951 , 0.2500049 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction vs. probability prediction\n",
    "# we ultimately are interested in m.predict(X) because it answers our question of \n",
    "# who survives and who doesn't\n",
    "\n",
    "# The model optimizes on m.predict_proba(X); these are the probabilitie estimates\n",
    "m.predict_proba(X) # [probability_of_dying, probability_of_surviving] for each passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m.predict_proba(X)) # We have one prediction per passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6085336468537561"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, m.predict_proba(X))\n",
    "# m.fit() will tweak our parameters b and w in order to minimize this log_loss\n",
    "# So if we calculated the log_loss with any other parameters, it will be bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sigmoid function\n",
    "def sigmoid(x, b, w):\n",
    "    return 1/(1+np.exp(-(b+x*w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4325500494239256"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = m.intercept_[0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8437120730506076"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = m.coef_[0][0]\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2500048973332678"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the probability of survival of a member of Pclass 1\n",
    "sigmoid(Pclass, b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
